* [2021-09-29]

** 一、主要收获、成果
   汇总出本次汇报最重要的内容，如本周最主要的收获、最新的实验成果，分点列出
   1.
   2.
      
** 二、具体做法、具体内容
   对于实验成果，就将实验的具体内容和实验过程叙述出来；
   对于收获，叙述出有所收获的具体事件、具体内容。
   
** 三、思考与总结
   自由发挥。
   
** 四、疑问或困扰
   可以将一周以来遇到的疑问或困扰罗列出来（生活、学习、实验）
   1.
   2.



* [2021-10-6]
** 一、主要收获、成果
   1.阅读了2020年1月发表的流体力学年刊中关于机器学习的部分。
   Annual Review of Fluid Mechanics- Machine Learning(ML) for Fluid Mechanics
   
   本文介绍了流体力学中ML的过去历史、当前发展和新兴机遇。概述了基本的ML方法，并讨论了
   它们在理解、建模、优化和控制流体流动方面的用途。

   通过查阅其它资料，对机器学习的基本知识有了一定的了解。
   
** 二、具体做法、具体内容。
  一、机器学习基础
   ML现在正在流体力学领域迅速取得进展。这些学习算法可分为监督学习、半监督学习和无监督学习
   ，具体取决于学习机（LM）数据的可用信息。
   
   *** 监督学习
       监督式学习是拥有一个输入变量（自变量）和一个输出变量（因变量），使用某种算法去学习从输入
       到输出之间的映射函数。目标是得到足够好的近似映射函数，当输入新的变量时可以以此预测输出变量。
       
       1. Neural networks(NNs)神经网络：NNs的力量和灵活性来源于它们的模块化结构，其基础是神经
       元作为中心构造元素，是对人脑神经元的模仿。每个神经元接收一个输入，通过一个激活函数处理它，
       并产生一个输出。多个神经元可以组合成不同的结构，反映有关问题和数据类型的知识.
       2.分类：随机森林和支持向量机。它可以根据先验标记的训练数据确定一组度量的标签或类别，这也许是
       最古老的学习方法。
       3.近邻算法（KNN，K-NearestNeighbor）：所谓K最近邻，就是K个最近的邻居的意思，说的是每个样本
       都可以用它最接近的K个邻近值来代表。如果一个样本在特征空间中的K个最相似（即特征空间中最邻近）
       的样本中的大多数属于某一个类别，则该样本也属于这个类别。
       4.决策树：在已知各种情况发生概率的基础上，通过构成决策树来求取净现值的期望值大于等于零的概率
       ，评价项目风险，判断其可行性的决策分析方法，是直观运用概率分析的一种图解法。由于这种决策分支
       画成图形很像一棵树的枝干，故称决策树。

   *** 无监督学习
       这个学习任务意味着通过指定某些全局标准从数据中提取特征，而不需要对结果进行监督，也不需要一个
       真实的标签。这里涉及的问题类型包括降维、量化和聚类。
   
       1.降维I：适当的正交分解、主成分分析和自动编码器。可以看作是一个信息过滤瓶颈，在数据被映射回环
       境维度之前，数据是通过低维表示进行处理的。经典的POD算法属于这一类学习。
       2.降维II：离散主曲线和自组织映射。
       3.聚类： 聚类是一种无监督学习技术，它识别数据中的相似组。最常见的算法是k-means聚类，它将数据划
       分为k个聚类簇；观察属于最近质心的簇，从而将数据空间划分为Voronoi单元。
       4.矢量量化：矢量量化器识别数据的具有代表性的点，这些数据可以被划分成预定数量的簇。然后可以使用这
       些点来代替完整的数据集，以便将来的样本可以被它们近似。

   *** 半监督学习
       半监督学习算法在部分监督下运行，要么使用有限的标记训练数据，要么使用来自环境的其他纠正信息。这一
       类的两种算法是生成性对抗网络（GANs）和RL。

       1.生成对抗性网络：GANS是一种学习算法，它产生一个生成模型，即根据概率分布产生数据的模型，该概率分
       布模拟用于其训练的数据的概率分布。
       2.强化学习(Reinforcement learning )：RL是一个解决问题的数学框架，它意味着代理与其环境的目标导定向交。


二、基于机器学习的流程建模：1.流动特征提取。2.流动动力学建模。

三、基于机器学习的流量优化与控制

** 三、思考与总结
   1.机器学习（ML）需要强大的信息处理算法，这些算法与流体的建模、优化和控制相关。有效的
   问题解决者需要具备ML方面的专业知识和流体力学方面的深入知识。
   2.流体力学历来关注大数据。几十年来，它一直使用ML来理解、预测、优化和控制流量。目前
   ，ML能力正在以令人难以置信的速度发展，流体力学正开始挖掘这些强大方法的全部潜力。
   3.流体力学中的许多任务，如降阶建模、形状优化和反馈控制，都可以作为优化和回归任务。ML
   可以提高优化性能，缩短收敛时间。ML还用于降维和识别低维流形和离散流型解。
   4.传统上，流量控制策略基于从理解到建模再到控制的精确顺序。ML模型建议更大的灵活性，
   并在数据驱动和第一原理方法之间迭代。

   5.近邻算法小结
   假设X_test为待标记的样本，X_train为已标记的数据集，算法原理的伪代码如下：
   遍历X_train中的所有样本，计算每个样本与X_test的距离，并把距离保存在Distance数组中。
   对Distance数组进行排序，取距离最近的k个点，记为X_knn。
   在X_knn中统计每个类别的个数。
   待标记样本的类别，就是在X_knn中样本个数最多的那个类别。
   
   优点：
   精度高，对异常值不敏感，无数据输入假定；
   KNN 是一种在线技术，新数据可以直接加入数据集而不必进行重新训练；
   KNN 理论简单，容易实现。

   缺点：
   对于样本容量大的数据集计算量比较大，即计算复杂度高；
   必须保存全部数据集，即空间复杂度高；
   KNN 每一次分类都会重新进行一次全局运算；
   样本不平衡时，预测偏差比较大。如：某一类的样本比较少，而其它类样本比较多；
   K值大小的选择；
   KNN 无法给出基础结构信息，无法知晓平均实例样本与典型实例样本具有什么特征，即无法给出数据的内在含义。
   适用数据类型： 数值型和标称型。

   应用领域： 文本分类；模式识别；聚类分析；多分类领域。

   6.决策树算法小结
   在构造决策树时，我们需要解决的第一个问题就是，当前数据集上那个特征在划分数据分类时起决定性的作用。
   为了找到决定性的特征，划分出最好的结果，我们必须评估每个特征。完成测试之后，原始数据集就会被划分
   为几个数据子集。这些数据子集会分布在第一个决策点的所有分支上。如果某个分支下的数据属于同一类型，则
   已正确划分数据类型，如过不同，则需重复划分数据子集。划分数据子集的算法和原始数据相同，直到所有的节点
   都是同一类型为止。

   优点：
   决策树易于理解和解释，可以可视化分析，容易提取出规则；
   计算复杂度不高，对中间值的缺失不敏感，可以处理不相关特征数据；
   测试数据集时，运行速度比较快；
   决策树可以很好的扩展到大型数据库中，同时它的大小独立于数据库大小。
   
   缺点：
   容易出现过拟合问题。
   对缺失数据处理比较困难。
   忽略数据集中属性的相互关联。
   ID3 算法计算信息增益时结果偏向数值比较多的特征。
   
   适用数据类型： 标称型和数值型。
   
** 四、疑问或困惑
   1.因为python水平有限，对于机器学习的具体算法实现理解的不是很清楚。现阶段需要加强对python的学习。
   2.加强对机器学习相关概念的认识。
   3.需要学习流体力学相关知识。
